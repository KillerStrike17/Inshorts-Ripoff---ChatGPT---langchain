{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install newsdataapi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import json\n",
    "import os \n",
    "import numpy as np\n",
    "from newsdataapi import NewsDataApiClient\n",
    "from langchain.agents import initialize_agent, Tool\n",
    "from langchain.agents import AgentType\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.experimental.plan_and_execute import PlanAndExecute, load_agent_executor, load_chat_planner\n",
    "import credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news(searchquery:str=None)->list:\n",
    "    '''\n",
    "    input searchquery is a string that takes in a variable that needs to be searched. It is an optional variable\n",
    "    The function returns a list of string of latest news\n",
    "    '''\n",
    "    api = NewsDataApiClient(apikey=credentials.NEWSDATA_KEY)\n",
    "    \n",
    "    page=None\n",
    "    news= []\n",
    "    # while True:\n",
    "    #     response = api.news_api(page = page,q= searchquery , country = \"us\")\n",
    "    #     page = response.get('nextPage',None)\n",
    "    #     if not page:\n",
    "    #         break\n",
    "    #     else:\n",
    "    #         news.append(page)\n",
    "    if searchquery:\n",
    "        response = api.news_api(q= searchquery,country = \"in\", language = 'en')\n",
    "    else:\n",
    "        response = api.news_api(country = \"in\", language = 'en')\n",
    "    \n",
    "    \n",
    "    news = [content['content'] for content in response['results']]\n",
    "    # news_dict = {i:content['content'] for i,content in enumerate(response['results'])}\n",
    "\n",
    "        \n",
    "    # {\"1\":\"asda\",\"2\":\"asd\"}        \n",
    "    return news[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def processNews( news_dict:dict):\n",
    "#     # news_dict = get_news(searchquery)\n",
    "#     for news in news_dict.values():\n",
    "#         prompt = \"Summarize the following news under 60 words and return only the summarized news. It should be stricty under 60 words. The news is as follows: \" + news\n",
    "#         yield prompt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x= get_news()\n",
    "\n",
    "api = NewsDataApiClient(apikey=credentials.NEWSDATA_KEY)\n",
    "# dir(api.news_api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "newssummary = Tool(\n",
    "    name='newssummary',\n",
    "    func = get_news,\n",
    "    description='get latest news as a list of string'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model='gpt-3.5-turbo-0613',openai_api_key=credentials.OPENAI_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [newssummary]\n",
    "agent = initialize_agent(tools,llm,agent=AgentType.OPENAI_FUNCTIONS,verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "langchain.debug = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"input\": \"get the latest news and summarize it under strictly 50 tokens, else you will be punished\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: You are a helpful AI assistant.\\nHuman: get the latest news and summarize it under strictly 50 tokens, else you will be punished\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 2:llm:ChatOpenAI] [1.21s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"\",\n",
      "        \"generation_info\": null,\n",
      "        \"message\": {\n",
      "          \"content\": \"\",\n",
      "          \"additional_kwargs\": {\n",
      "            \"function_call\": {\n",
      "              \"name\": \"newssummary\",\n",
      "              \"arguments\": \"{\\n  \\\"text\\\": \\\"latest news\\\"\\n}\"\n",
      "            }\n",
      "          },\n",
      "          \"example\": false\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": {\n",
      "    \"token_usage\": {\n",
      "      \"prompt_tokens\": 77,\n",
      "      \"completion_tokens\": 18,\n",
      "      \"total_tokens\": 95\n",
      "    },\n",
      "    \"model_name\": \"gpt-3.5-turbo-0613\"\n",
      "  },\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[tool/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 3:tool:newssummary] Entering Tool run with input:\n",
      "\u001b[0m\"{'text': 'latest news'}\"\n",
      "\u001b[36;1m\u001b[1;3m[tool/end]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 3:tool:newssummary] [1.53s] Exiting Tool run with output:\n",
      "\u001b[0m\"MongoDB announced the general availability of MongoDB Relational Migrator, a new tool that simplifies application migration and transformation—from legacy relational to modern document-based data models—providing organizations a streamlined way to improve operational efficiency and get more out of their data. Data is the foundation of every application with a large portion of it still residing in legacy relational databases where it can’t easily support emerging applications that leverage new technologies using a fully managed, multi-cloud developer data platform with best-in-class security, resilience, and performance. Already in use by tens of thousands of customers and millions of developers around the world, MongoDB Atlas’s flexible document model and scale-out capabilities are helping customers build modern applications that leverage the latest technologies, empowering them to reimagine business operations and end-user experiences. Now, with MongoDB Relational Migrator, more organizations across all industries can quickly, easily, cost-effectively, and with little-to-no risk migrate from legacy databases and embrace the future. Organizations today have a clear imperative—modernize legacy applications to prepare their businesses for the future. New technologies like generative AI and large language models (LLMs) are another wave in a series of innovations over the past few decades that are opening up new possibilities for what’s possible with software and data for business operations and end-user experiences. Organizations of all sizes want to be able to make use of new technologies to transform their businesses. However, many companies remain locked-in to legacy relational databases in the backend of their applications, limiting their ability to adapt and modernize. These legacy databases are rigid, unadaptable, and difficult to use for supporting modern applications because of the complexity involved in mapping relationships between data when application requirements inevitably change. Additionally, because legacy databases were designed for an era before the advent of cloud computing, it is difficult to scale these databases without incurring significant costs. As a result, incorporating new technologies, quickly adapting to dynamic market changes, or continuously inventing new experiences for end-users are out of reach. For these reasons, customers are increasingly looking to migrate to a more flexible and scalable document-based data model that is easier to use and adapt. However, there is often considerable time, cost, and risk associated with these migrations because they require highly specialized tooling and knowledge to assess existing applications and prepare data for migration. Even then, the migration process can result in data loss, application downtime, and a migrated application that does not function as intended. Together, these challenges often prevent even the most well-funded and technologically savvy organizations from being able to cost-effectively migrate and modernize their applications so they can be ready for the future. With MongoDB Relational Migrator, customers can migrate and modernize legacy applications without the time, cost, and risk typically associated with these projects—making it significantly faster and easier to optimize business operations and inspire developer innovation. MongoDB Relational Migrator analyzes legacy databases, automatically generates new data schema and code, and then executes a seamless migration to MongoDB Atlas with no downtime required. Customers can quickly get started by simply connecting MongoDB Relational Migrator to their existing application database (e.g., Oracle, Microsoft SQL Server, MySQL, and PostgreSQL) for assessment. After analyzing the application data, MongoDB Relational Migrator suggests a new data schema, transforms and migrates data to MongoDB Atlas with the ability to run continuous sync jobs for zero-downtime migrations, and generates optimized code for working with data in the new, modernized application. Customers can then run the modernized application in a testing environment to ensure it is operating as intended before deploying it to production. Using MongoDB Relational Migrator, organizations of all shapes and sizes can eliminate the barriers and heavy lifting associated with migrating and modernizing applications to ensure they are better equipped to build the next generation of highly engaging, mission-critical applications. “Customers often tell us it’s crucial that they modernize their legacy applications so they can quickly build new end-user experiences that take advantage of game-changing technologies and ship new features at high velocity. But they also say that it’s too risky, expensive, and time consuming, or that they just don’t know how to get started,” said Sahir Azam, Chief Product Officer at MongoDB. “With MongoDB Relational Migrator, customers can now realize the full potential of software, data, and new technologies like generative AI by migrating and modernizing their legacy applications with a seamless, zero-downtime migration experience and without the heavy lifting. It’s now easier than ever to modernize applications and create innovative end-user experiences at the speed and scale that modern applications require with MongoDB Atlas.” Customers that want a tailored modernization experience can work with MongoDB Professional Services and MongoDB Ecosystem Partners (e.g., Accenture, Capgemini, Globant, and Tech Mahindra) to unlock what’s possible with the next generation of software and data. Accenture is a global professional services company with leading capabilities in digital, cloud, and security. “Together, Accenture and MongoDB provide unparalleled expertise to help customers modernize their environments and adopt a cloud-first approach throughout their organizations. Our partnership helps enterprises unlock value from data by modernizing and building new applications faster,” said Stephen Meyer, Associate Director, Cloud First Software Engineering, NoSQL Lead at Accenture. “Along with Accenture’s own capabilities and solutions, the release of MongoDB Relational Migrator will enable customers to accelerate their modernization strategies.” Capgemini is a global leader in partnering with companies to transform and manage their business by harnessing the power of technology. “Capgemini’s collaboration with MongoDB has been a stepping stone to enhance strong migration offerings and modernizing legacy systems. This has enabled customers to reap the benefits of new technology and helped them build the next generation of applications,” said Prasad Bakshi, Global Head of the Database Migration Practice at Capgemini. “Coupled with Capgemini’s proprietary Data Convert & Compare (DCC) accelerator, MongoDB Relational Migrator will enable us to provide unique database migration as-a-service capabilities to our customers. We’re excited to be able to accelerate the modernization journey for organizations of all shapes and sizes.” Globant is a digitally native company focused on reinventing businesses through innovative technology solutions. “By leveraging MongoDB, our customers have seen immense benefits including accelerated development, transformation, cost savings and legacy modernization,” said Nicolás Ávila, Chief Technology Officer for North America at Globant. “We are seeing more and more customers leverage MongoDB’s Relational Migrator to migrate from traditional, relational databases to MongoDB Atlas with no downtime, making it a seamless and efficient solution. We look forward to using MongoDB tools to build more unique, modern digital experiences for our customers that help them reinvent their industries and outpace their competition.” Nationwide is the world’s largest building society as well as one of the largest savings providers and a top-three provider of mortgages in the UK. “Recently, I had the chance to employ MongoDB’s Relational Migrator and I was genuinely amazed by its outstanding performance,” said Peter Madeley, Senior Software Engineer at Nationwide Building Society. “The user interface of the tool is intuitively designed and the entity relationship diagrams proved to be invaluable in offering a detailed visual representation of my data structures. This migrator not only streamlines the transition from relational data to a document model, but it also ensures data integrity and offers a high degree of adaptability.” Founded in 2016, Powerledger develops software solutions for the tracking, tracing, and trading of renewable energy. “We needed to demonstrate our platform’s ability to ingest a much higher volume of data and cater to the one billion users we aim to serve in the future, which required a level of scalability and flexibility that our previous relational database couldn’t offer,” said Dr. Vivek Bhandari, CTO at Powerledger. “Migrating an entire database is a pretty bold and risky endeavor. Our main priorities—and challenges—were to do a complete data platform migration, as well as add in scalability and flexibility without disrupting the platform or hindering data security. Amazingly, using MongoDB Relational Migrator, we didn’t experience any disruption or downtime.” Tech Mahindra is a leading provider of digital transformation, consulting, and business re-engineering services and solutions. “The partnership with MongoDB helps unlock the full potential of data, data transformation, migration, and data consistency,” said Kunal Purohit, Chief Digital Services Officer at Tech Mahindra. “Tech Mahindra and MongoDB, together, will navigate the vast sea of information, harness its power, and chart a course towards industry-wide transformation journeys. Our enterprise customers can hugely benefit from this tool by leveraging its readily available migration interfaces, which in turn will help them quickly onboard the required data interfaces onto the target platform.”\"\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 4:llm:ChatOpenAI] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: You are a helpful AI assistant.\\nHuman: get the latest news and summarize it under strictly 50 tokens, else you will be punished\\nAI: {'name': 'newssummary', 'arguments': '{\\\\n  \\\"text\\\": \\\"latest news\\\"\\\\n}'}\\nFunction: MongoDB announced the general availability of MongoDB Relational Migrator, a new tool that simplifies application migration and transformation—from legacy relational to modern document-based data models—providing organizations a streamlined way to improve operational efficiency and get more out of their data. Data is the foundation of every application with a large portion of it still residing in legacy relational databases where it can’t easily support emerging applications that leverage new technologies using a fully managed, multi-cloud developer data platform with best-in-class security, resilience, and performance. Already in use by tens of thousands of customers and millions of developers around the world, MongoDB Atlas’s flexible document model and scale-out capabilities are helping customers build modern applications that leverage the latest technologies, empowering them to reimagine business operations and end-user experiences. Now, with MongoDB Relational Migrator, more organizations across all industries can quickly, easily, cost-effectively, and with little-to-no risk migrate from legacy databases and embrace the future. Organizations today have a clear imperative—modernize legacy applications to prepare their businesses for the future. New technologies like generative AI and large language models (LLMs) are another wave in a series of innovations over the past few decades that are opening up new possibilities for what’s possible with software and data for business operations and end-user experiences. Organizations of all sizes want to be able to make use of new technologies to transform their businesses. However, many companies remain locked-in to legacy relational databases in the backend of their applications, limiting their ability to adapt and modernize. These legacy databases are rigid, unadaptable, and difficult to use for supporting modern applications because of the complexity involved in mapping relationships between data when application requirements inevitably change. Additionally, because legacy databases were designed for an era before the advent of cloud computing, it is difficult to scale these databases without incurring significant costs. As a result, incorporating new technologies, quickly adapting to dynamic market changes, or continuously inventing new experiences for end-users are out of reach. For these reasons, customers are increasingly looking to migrate to a more flexible and scalable document-based data model that is easier to use and adapt. However, there is often considerable time, cost, and risk associated with these migrations because they require highly specialized tooling and knowledge to assess existing applications and prepare data for migration. Even then, the migration process can result in data loss, application downtime, and a migrated application that does not function as intended. Together, these challenges often prevent even the most well-funded and technologically savvy organizations from being able to cost-effectively migrate and modernize their applications so they can be ready for the future. With MongoDB Relational Migrator, customers can migrate and modernize legacy applications without the time, cost, and risk typically associated with these projects—making it significantly faster and easier to optimize business operations and inspire developer innovation. MongoDB Relational Migrator analyzes legacy databases, automatically generates new data schema and code, and then executes a seamless migration to MongoDB Atlas with no downtime required. Customers can quickly get started by simply connecting MongoDB Relational Migrator to their existing application database (e.g., Oracle, Microsoft SQL Server, MySQL, and PostgreSQL) for assessment. After analyzing the application data, MongoDB Relational Migrator suggests a new data schema, transforms and migrates data to MongoDB Atlas with the ability to run continuous sync jobs for zero-downtime migrations, and generates optimized code for working with data in the new, modernized application. Customers can then run the modernized application in a testing environment to ensure it is operating as intended before deploying it to production. Using MongoDB Relational Migrator, organizations of all shapes and sizes can eliminate the barriers and heavy lifting associated with migrating and modernizing applications to ensure they are better equipped to build the next generation of highly engaging, mission-critical applications. “Customers often tell us it’s crucial that they modernize their legacy applications so they can quickly build new end-user experiences that take advantage of game-changing technologies and ship new features at high velocity. But they also say that it’s too risky, expensive, and time consuming, or that they just don’t know how to get started,” said Sahir Azam, Chief Product Officer at MongoDB. “With MongoDB Relational Migrator, customers can now realize the full potential of software, data, and new technologies like generative AI by migrating and modernizing their legacy applications with a seamless, zero-downtime migration experience and without the heavy lifting. It’s now easier than ever to modernize applications and create innovative end-user experiences at the speed and scale that modern applications require with MongoDB Atlas.” Customers that want a tailored modernization experience can work with MongoDB Professional Services and MongoDB Ecosystem Partners (e.g., Accenture, Capgemini, Globant, and Tech Mahindra) to unlock what’s possible with the next generation of software and data. Accenture is a global professional services company with leading capabilities in digital, cloud, and security. “Together, Accenture and MongoDB provide unparalleled expertise to help customers modernize their environments and adopt a cloud-first approach throughout their organizations. Our partnership helps enterprises unlock value from data by modernizing and building new applications faster,” said Stephen Meyer, Associate Director, Cloud First Software Engineering, NoSQL Lead at Accenture. “Along with Accenture’s own capabilities and solutions, the release of MongoDB Relational Migrator will enable customers to accelerate their modernization strategies.” Capgemini is a global leader in partnering with companies to transform and manage their business by harnessing the power of technology. “Capgemini’s collaboration with MongoDB has been a stepping stone to enhance strong migration offerings and modernizing legacy systems. This has enabled customers to reap the benefits of new technology and helped them build the next generation of applications,” said Prasad Bakshi, Global Head of the Database Migration Practice at Capgemini. “Coupled with Capgemini’s proprietary Data Convert & Compare (DCC) accelerator, MongoDB Relational Migrator will enable us to provide unique database migration as-a-service capabilities to our customers. We’re excited to be able to accelerate the modernization journey for organizations of all shapes and sizes.” Globant is a digitally native company focused on reinventing businesses through innovative technology solutions. “By leveraging MongoDB, our customers have seen immense benefits including accelerated development, transformation, cost savings and legacy modernization,” said Nicolás Ávila, Chief Technology Officer for North America at Globant. “We are seeing more and more customers leverage MongoDB’s Relational Migrator to migrate from traditional, relational databases to MongoDB Atlas with no downtime, making it a seamless and efficient solution. We look forward to using MongoDB tools to build more unique, modern digital experiences for our customers that help them reinvent their industries and outpace their competition.” Nationwide is the world’s largest building society as well as one of the largest savings providers and a top-three provider of mortgages in the UK. “Recently, I had the chance to employ MongoDB’s Relational Migrator and I was genuinely amazed by its outstanding performance,” said Peter Madeley, Senior Software Engineer at Nationwide Building Society. “The user interface of the tool is intuitively designed and the entity relationship diagrams proved to be invaluable in offering a detailed visual representation of my data structures. This migrator not only streamlines the transition from relational data to a document model, but it also ensures data integrity and offers a high degree of adaptability.” Founded in 2016, Powerledger develops software solutions for the tracking, tracing, and trading of renewable energy. “We needed to demonstrate our platform’s ability to ingest a much higher volume of data and cater to the one billion users we aim to serve in the future, which required a level of scalability and flexibility that our previous relational database couldn’t offer,” said Dr. Vivek Bhandari, CTO at Powerledger. “Migrating an entire database is a pretty bold and risky endeavor. Our main priorities—and challenges—were to do a complete data platform migration, as well as add in scalability and flexibility without disrupting the platform or hindering data security. Amazingly, using MongoDB Relational Migrator, we didn’t experience any disruption or downtime.” Tech Mahindra is a leading provider of digital transformation, consulting, and business re-engineering services and solutions. “The partnership with MongoDB helps unlock the full potential of data, data transformation, migration, and data consistency,” said Kunal Purohit, Chief Digital Services Officer at Tech Mahindra. “Tech Mahindra and MongoDB, together, will navigate the vast sea of information, harness its power, and chart a course towards industry-wide transformation journeys. Our enterprise customers can hugely benefit from this tool by leveraging its readily available migration interfaces, which in turn will help them quickly onboard the required data interfaces onto the target platform.”\"\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 1.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-sTxGXte3ziCUC03xQshXnu9v on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 2.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-sTxGXte3ziCUC03xQshXnu9v on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues..\n",
      "Retrying langchain.chat_models.openai.ChatOpenAI.completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised RateLimitError: Rate limit reached for default-gpt-3.5-turbo in organization org-sTxGXte3ziCUC03xQshXnu9v on requests per min. Limit: 3 / min. Please try again in 20s. Contact us through our help center at help.openai.com if you continue to have issues..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31;1m\u001b[1;3m[chain/error]\u001b[0m \u001b[1m[1:chain:AgentExecutor > 4:llm:ChatOpenAI] [9.11s] Chain run errored with error:\n",
      "\u001b[0m\"KeyboardInterrupt()\"\n",
      "\u001b[31;1m\u001b[1;3m[chain/error]\u001b[0m \u001b[1m[1:chain:AgentExecutor] [11.84s] Chain run errored with error:\n",
      "\u001b[0m\"KeyboardInterrupt()\"\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[38], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m response \u001b[39m=\u001b[39m agent\u001b[39m.\u001b[39;49mrun(\u001b[39m\"\u001b[39;49m\u001b[39mget the latest news and summarize it under strictly 50 tokens, else you will be punished\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\langchain\\lib\\site-packages\\langchain\\chains\\base.py:290\u001b[0m, in \u001b[0;36mChain.run\u001b[1;34m(self, callbacks, tags, *args, **kwargs)\u001b[0m\n\u001b[0;32m    288\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m!=\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    289\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m`run` supports only one positional argument.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m--> 290\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m(args[\u001b[39m0\u001b[39;49m], callbacks\u001b[39m=\u001b[39;49mcallbacks, tags\u001b[39m=\u001b[39;49mtags)[_output_key]\n\u001b[0;32m    292\u001b[0m \u001b[39mif\u001b[39;00m kwargs \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m args:\n\u001b[0;32m    293\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(kwargs, callbacks\u001b[39m=\u001b[39mcallbacks, tags\u001b[39m=\u001b[39mtags)[_output_key]\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\langchain\\lib\\site-packages\\langchain\\chains\\base.py:166\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, include_run_info)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    165\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n\u001b[1;32m--> 166\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    167\u001b[0m run_manager\u001b[39m.\u001b[39mon_chain_end(outputs)\n\u001b[0;32m    168\u001b[0m final_outputs: Dict[\u001b[39mstr\u001b[39m, Any] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprep_outputs(\n\u001b[0;32m    169\u001b[0m     inputs, outputs, return_only_outputs\n\u001b[0;32m    170\u001b[0m )\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\langchain\\lib\\site-packages\\langchain\\chains\\base.py:160\u001b[0m, in \u001b[0;36mChain.__call__\u001b[1;34m(self, inputs, return_only_outputs, callbacks, tags, include_run_info)\u001b[0m\n\u001b[0;32m    154\u001b[0m run_manager \u001b[39m=\u001b[39m callback_manager\u001b[39m.\u001b[39mon_chain_start(\n\u001b[0;32m    155\u001b[0m     dumpd(\u001b[39mself\u001b[39m),\n\u001b[0;32m    156\u001b[0m     inputs,\n\u001b[0;32m    157\u001b[0m )\n\u001b[0;32m    158\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    159\u001b[0m     outputs \u001b[39m=\u001b[39m (\n\u001b[1;32m--> 160\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(inputs, run_manager\u001b[39m=\u001b[39;49mrun_manager)\n\u001b[0;32m    161\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[0;32m    162\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call(inputs)\n\u001b[0;32m    163\u001b[0m     )\n\u001b[0;32m    164\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    165\u001b[0m     run_manager\u001b[39m.\u001b[39mon_chain_error(e)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\langchain\\lib\\site-packages\\langchain\\agents\\agent.py:957\u001b[0m, in \u001b[0;36mAgentExecutor._call\u001b[1;34m(self, inputs, run_manager)\u001b[0m\n\u001b[0;32m    955\u001b[0m \u001b[39m# We now enter the agent loop (until it returns something).\u001b[39;00m\n\u001b[0;32m    956\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_should_continue(iterations, time_elapsed):\n\u001b[1;32m--> 957\u001b[0m     next_step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_take_next_step(\n\u001b[0;32m    958\u001b[0m         name_to_tool_map,\n\u001b[0;32m    959\u001b[0m         color_mapping,\n\u001b[0;32m    960\u001b[0m         inputs,\n\u001b[0;32m    961\u001b[0m         intermediate_steps,\n\u001b[0;32m    962\u001b[0m         run_manager\u001b[39m=\u001b[39;49mrun_manager,\n\u001b[0;32m    963\u001b[0m     )\n\u001b[0;32m    964\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(next_step_output, AgentFinish):\n\u001b[0;32m    965\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_return(\n\u001b[0;32m    966\u001b[0m             next_step_output, intermediate_steps, run_manager\u001b[39m=\u001b[39mrun_manager\n\u001b[0;32m    967\u001b[0m         )\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\langchain\\lib\\site-packages\\langchain\\agents\\agent.py:762\u001b[0m, in \u001b[0;36mAgentExecutor._take_next_step\u001b[1;34m(self, name_to_tool_map, color_mapping, inputs, intermediate_steps, run_manager)\u001b[0m\n\u001b[0;32m    756\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Take a single step in the thought-action-observation loop.\u001b[39;00m\n\u001b[0;32m    757\u001b[0m \n\u001b[0;32m    758\u001b[0m \u001b[39mOverride this to take control of how the agent makes and acts on choices.\u001b[39;00m\n\u001b[0;32m    759\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    760\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    761\u001b[0m     \u001b[39m# Call the LLM to see what to do.\u001b[39;00m\n\u001b[1;32m--> 762\u001b[0m     output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39magent\u001b[39m.\u001b[39mplan(\n\u001b[0;32m    763\u001b[0m         intermediate_steps,\n\u001b[0;32m    764\u001b[0m         callbacks\u001b[39m=\u001b[39mrun_manager\u001b[39m.\u001b[39mget_child() \u001b[39mif\u001b[39;00m run_manager \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    765\u001b[0m         \u001b[39m*\u001b[39m\u001b[39m*\u001b[39minputs,\n\u001b[0;32m    766\u001b[0m     )\n\u001b[0;32m    767\u001b[0m \u001b[39mexcept\u001b[39;00m OutputParserException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    768\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandle_parsing_errors, \u001b[39mbool\u001b[39m):\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\langchain\\lib\\site-packages\\langchain\\agents\\openai_functions_agent\\base.py:209\u001b[0m, in \u001b[0;36mOpenAIFunctionsAgent.plan\u001b[1;34m(self, intermediate_steps, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m prompt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprompt\u001b[39m.\u001b[39mformat_prompt(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfull_inputs)\n\u001b[0;32m    208\u001b[0m messages \u001b[39m=\u001b[39m prompt\u001b[39m.\u001b[39mto_messages()\n\u001b[1;32m--> 209\u001b[0m predicted_message \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mllm\u001b[39m.\u001b[39;49mpredict_messages(\n\u001b[0;32m    210\u001b[0m     messages, functions\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunctions, callbacks\u001b[39m=\u001b[39;49mcallbacks\n\u001b[0;32m    211\u001b[0m )\n\u001b[0;32m    212\u001b[0m agent_decision \u001b[39m=\u001b[39m _parse_ai_message(predicted_message)\n\u001b[0;32m    213\u001b[0m \u001b[39mreturn\u001b[39;00m agent_decision\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\langchain\\lib\\site-packages\\langchain\\chat_models\\base.py:258\u001b[0m, in \u001b[0;36mBaseChatModel.predict_messages\u001b[1;34m(self, messages, stop, **kwargs)\u001b[0m\n\u001b[0;32m    256\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     _stop \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(stop)\n\u001b[1;32m--> 258\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(messages, stop\u001b[39m=\u001b[39m_stop, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\langchain\\lib\\site-packages\\langchain\\chat_models\\base.py:208\u001b[0m, in \u001b[0;36mBaseChatModel.__call__\u001b[1;34m(self, messages, stop, callbacks, **kwargs)\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\n\u001b[0;32m    202\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    203\u001b[0m     messages: List[BaseMessage],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[0;32m    207\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m BaseMessage:\n\u001b[1;32m--> 208\u001b[0m     generation \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgenerate(\n\u001b[0;32m    209\u001b[0m         [messages], stop\u001b[39m=\u001b[39mstop, callbacks\u001b[39m=\u001b[39mcallbacks, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[0;32m    210\u001b[0m     )\u001b[39m.\u001b[39mgenerations[\u001b[39m0\u001b[39m][\u001b[39m0\u001b[39m]\n\u001b[0;32m    211\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(generation, ChatGeneration):\n\u001b[0;32m    212\u001b[0m         \u001b[39mreturn\u001b[39;00m generation\u001b[39m.\u001b[39mmessage\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\langchain\\lib\\site-packages\\langchain\\chat_models\\base.py:102\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, **kwargs)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    101\u001b[0m     run_manager\u001b[39m.\u001b[39mon_llm_error(e)\n\u001b[1;32m--> 102\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[0;32m    103\u001b[0m llm_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_combine_llm_outputs([res\u001b[39m.\u001b[39mllm_output \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m results])\n\u001b[0;32m    104\u001b[0m generations \u001b[39m=\u001b[39m [res\u001b[39m.\u001b[39mgenerations \u001b[39mfor\u001b[39;00m res \u001b[39min\u001b[39;00m results]\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\langchain\\lib\\site-packages\\langchain\\chat_models\\base.py:94\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[1;34m(self, messages, stop, callbacks, tags, **kwargs)\u001b[0m\n\u001b[0;32m     90\u001b[0m new_arg_supported \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39msignature(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate)\u001b[39m.\u001b[39mparameters\u001b[39m.\u001b[39mget(\n\u001b[0;32m     91\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mrun_manager\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     92\u001b[0m )\n\u001b[0;32m     93\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 94\u001b[0m     results \u001b[39m=\u001b[39m [\n\u001b[0;32m     95\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(m, stop\u001b[39m=\u001b[39mstop, run_manager\u001b[39m=\u001b[39mrun_manager, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     96\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[0;32m     97\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(m, stop\u001b[39m=\u001b[39mstop)\n\u001b[0;32m     98\u001b[0m         \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m messages\n\u001b[0;32m     99\u001b[0m     ]\n\u001b[0;32m    100\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    101\u001b[0m     run_manager\u001b[39m.\u001b[39mon_llm_error(e)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\langchain\\lib\\site-packages\\langchain\\chat_models\\base.py:95\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     90\u001b[0m new_arg_supported \u001b[39m=\u001b[39m inspect\u001b[39m.\u001b[39msignature(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate)\u001b[39m.\u001b[39mparameters\u001b[39m.\u001b[39mget(\n\u001b[0;32m     91\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mrun_manager\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m     92\u001b[0m )\n\u001b[0;32m     93\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     94\u001b[0m     results \u001b[39m=\u001b[39m [\n\u001b[1;32m---> 95\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(m, stop\u001b[39m=\u001b[39mstop, run_manager\u001b[39m=\u001b[39mrun_manager, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     96\u001b[0m         \u001b[39mif\u001b[39;00m new_arg_supported\n\u001b[0;32m     97\u001b[0m         \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generate(m, stop\u001b[39m=\u001b[39mstop)\n\u001b[0;32m     98\u001b[0m         \u001b[39mfor\u001b[39;00m m \u001b[39min\u001b[39;00m messages\n\u001b[0;32m     99\u001b[0m     ]\n\u001b[0;32m    100\u001b[0m \u001b[39mexcept\u001b[39;00m (\u001b[39mKeyboardInterrupt\u001b[39;00m, \u001b[39mException\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    101\u001b[0m     run_manager\u001b[39m.\u001b[39mon_llm_error(e)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\langchain\\lib\\site-packages\\langchain\\chat_models\\openai.py:359\u001b[0m, in \u001b[0;36mChatOpenAI._generate\u001b[1;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[0;32m    351\u001b[0m     message \u001b[39m=\u001b[39m _convert_dict_to_message(\n\u001b[0;32m    352\u001b[0m         {\n\u001b[0;32m    353\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: inner_completion,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    356\u001b[0m         }\n\u001b[0;32m    357\u001b[0m     )\n\u001b[0;32m    358\u001b[0m     \u001b[39mreturn\u001b[39;00m ChatResult(generations\u001b[39m=\u001b[39m[ChatGeneration(message\u001b[39m=\u001b[39mmessage)])\n\u001b[1;32m--> 359\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompletion_with_retry(messages\u001b[39m=\u001b[39mmessage_dicts, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n\u001b[0;32m    360\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_chat_result(response)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\langchain\\lib\\site-packages\\langchain\\chat_models\\openai.py:307\u001b[0m, in \u001b[0;36mChatOpenAI.completion_with_retry\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    303\u001b[0m \u001b[39m@retry_decorator\u001b[39m\n\u001b[0;32m    304\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_completion_with_retry\u001b[39m(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[0;32m    305\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclient\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 307\u001b[0m \u001b[39mreturn\u001b[39;00m _completion_with_retry(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\langchain\\lib\\site-packages\\tenacity\\__init__.py:289\u001b[0m, in \u001b[0;36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(f)\n\u001b[0;32m    288\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapped_f\u001b[39m(\u001b[39m*\u001b[39margs: t\u001b[39m.\u001b[39mAny, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw: t\u001b[39m.\u001b[39mAny) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m t\u001b[39m.\u001b[39mAny:\n\u001b[1;32m--> 289\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m(f, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkw)\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\langchain\\lib\\site-packages\\tenacity\\__init__.py:389\u001b[0m, in \u001b[0;36mRetrying.__call__\u001b[1;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    387\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(do, DoSleep):\n\u001b[0;32m    388\u001b[0m     retry_state\u001b[39m.\u001b[39mprepare_for_next_attempt()\n\u001b[1;32m--> 389\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msleep(do)\n\u001b[0;32m    390\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    391\u001b[0m     \u001b[39mreturn\u001b[39;00m do\n",
      "File \u001b[1;32md:\\Anaconda\\envs\\langchain\\lib\\site-packages\\tenacity\\nap.py:31\u001b[0m, in \u001b[0;36msleep\u001b[1;34m(seconds)\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msleep\u001b[39m(seconds: \u001b[39mfloat\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m     26\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[39m    Sleep strategy that delays execution for a given number of seconds.\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \n\u001b[0;32m     29\u001b[0m \u001b[39m    This is the default strategy, and may be mocked out for unit testing.\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m     time\u001b[39m.\u001b[39;49msleep(seconds)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "response = agent.run(\"get the latest news and summarize it under strictly 50 tokens, else you will be punished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x = [\"\n",
    "\n",
    "# print(x[0])\n",
    "# x[1]\n",
    "len(response.split(\" \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"Byju's, the edtech giant, is facing criticism from auditors and board exits, raising concerns about its financial transparency and corporate governance. The auditor, Deloitte, quit due to concerns about accounting practices and financial disclosures. Independent directors have also resigned, indicating potential governance issues. These challenges have affected Byju's image and investor confidence. Byju's has stated its commitment to transparency and good corporate governance. In other news, Indian fast bowler Navdeep Saini has been signed by Worcestershire for four months of matches in the County Championship. Startups in India raised only $103 million across 17 rounds in the last week, a significant decrease compared to last year. Funding activity for Indian startups has plunged, with Bengaluru-based pet food-maker Drools leading the funding activity this week. Robinhood, the trading app, has acquired credit card startup X1 for $95 million, aiming to deepen its relationship with customers and expand its revenue streams.\"\n",
    "len(x.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_articles['articles'])\n",
    "print(type(all_articles['articles'][0]['content']),len(all_articles['articles'][0]['content']),(all_articles['articles'][0]['content']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /v2/top-headlines/sources\n",
    "sources = newsapi.get_sources()\n",
    "sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = get_news()\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
